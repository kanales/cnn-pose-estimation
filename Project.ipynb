{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "from shutil import rmtree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import read_images, batch, similarity\n",
    "from model import cnn_model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(os.listdir('dataset/coarse/'))\n",
    "\n",
    "coarse = read_images('dataset/coarse/')\n",
    "fine = read_images('dataset/fine/')\n",
    "real = read_images('dataset/real/')\n",
    "train_idxs = ()\n",
    "with open('dataset/real/training_split.txt') as f:\n",
    "    train_idxs = set(int(x) for x in f.read().split(', '))\n",
    "test_idxs = set(range(len(real))) - train_idxs\n",
    "Sdb    = coarse\n",
    "Strain = fine + [real[i] for i in train_idxs]\n",
    "Stest  = [real[i] for i in test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CACHE_DIR = 'cache/'\n",
    "#rmtree(CACHE_DIR)\n",
    "#os.makedirs(CACHE_DIR)\n",
    "MODEL_PATH = os.path.join(CACHE_DIR,'cnn_model')\n",
    "INPUT_PATH = os.path.join(CACHE_DIR,'cnn_input')\n",
    "#os.makedirs(MODEL_PATH)\n",
    "#os.makedirs(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'cache/cnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb33314518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "cnn_descriptor = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train input\n",
    "def gen_train_input_fn(Sdb,Strain, batch_size):\n",
    "    #Sdb    = features['Sdb']\n",
    "    #Strain = features['Strain']\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(batch(Sdb,Strain,batch_size)))\n",
    "    assert(batch_size % 3 == 0)\n",
    "    def inner():\n",
    "        #b = batch(Sdb,Strain,batch_size)\n",
    "        #dataset = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(b))\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            batch(Sdb,Strain),\n",
    "            tf.float32,\n",
    "            tf.TensorShape([64, 64, 3])\n",
    "        )\n",
    "        return dataset.batch(batch_size)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = gen_train_input_fn(Sdb,Strain,300)\n",
    "for x in range(10,1000,10):\n",
    "    cnn_descriptor.train(\n",
    "        input_fn=train_input_fn,\n",
    "        max_steps=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ex3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ex3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from cache/cnn_model/model.ckpt-990\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ex3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "Sdb_img = np.array([x.img for x in Sdb])\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    np.array(Sdb_img),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "Sdb_descriptors = list(cnn_descriptor.predict(input_fn=eval_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from cache/cnn_model/model.ckpt-990\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "Stest_img = np.array([x.img for x in Stest])\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    Stest_img,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "Stest_descriptors = list(cnn_descriptor.predict(input_fn=eval_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "X, y = Sdb_descriptors, [x.cls for x in Sdb]\n",
    "neigh.fit(X,y)\n",
    "\n",
    "idxs = neigh.kneighbors(Stest_descriptors)[1]\n",
    "\n",
    "hist = np.array([0,0,0,0])\n",
    "N = len(Stest_descriptors)\n",
    "for i in range(N):\n",
    "    db = Sdb[idxs[i][0]]\n",
    "    test = Stest[i]\n",
    "\n",
    "    if db.cls != test.cls:\n",
    "        continue\n",
    "\n",
    "    theta = np.rad2deg(similarity(db.quat, test.quat))\n",
    "    if theta < 10:\n",
    "        hist[0] += 1\n",
    "    if theta < 20:\n",
    "        hist[1] += 1\n",
    "    if theta < 40:\n",
    "        hist[2] += 1\n",
    "    hist[3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.12917512,  1.56855508, 16.82967337])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * hist / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.1526968\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.04669378\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.0105207525\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.040376976\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.07209955\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.08518978\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.028880354\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.1770436\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.03647869\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.021683976\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.057673067\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.10664716\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 0.02856906\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "0 -0.0\n",
      "1 0.19254526\n",
      "1 0.143671\n",
      "1 0.24347326\n",
      "1 0.23592612\n",
      "1 0.18724397\n",
      "1 0.25170264\n",
      "1 0.22924598\n",
      "1 0.18130878\n",
      "1 0.13900813\n",
      "1 0.21081413\n",
      "1 0.11056859\n",
      "1 0.1494375\n",
      "1 0.124376684\n",
      "1 0.19166034\n",
      "1 0.13381031\n",
      "1 0.14112164\n",
      "1 0.23516339\n",
      "1 0.17041872\n",
      "1 0.2263786\n",
      "1 0.13079542\n",
      "1 0.30564657\n",
      "1 0.16674982\n",
      "1 0.24135189\n",
      "1 0.13150091\n",
      "1 0.13452907\n",
      "1 0.13607554\n",
      "1 0.17510092\n",
      "1 0.16822504\n",
      "1 0.38999686\n",
      "1 0.19161394\n",
      "1 0.20717485\n",
      "1 0.18773116\n",
      "1 0.20448074\n",
      "1 0.1851947\n",
      "1 0.26767707\n",
      "1 0.1590372\n",
      "1 0.10550439\n",
      "1 0.14013408\n",
      "1 0.24418443\n",
      "1 0.11893941\n",
      "1 0.19107206\n",
      "1 0.22227031\n",
      "1 0.2974642\n",
      "1 0.14401753\n",
      "1 0.16103932\n",
      "1 0.12969622\n",
      "1 0.16634703\n",
      "1 0.1674981\n",
      "1 0.15749158\n",
      "1 0.25699037\n",
      "1 0.19370155\n",
      "1 0.28041828\n",
      "1 0.1344755\n",
      "1 0.27504894\n",
      "1 0.21613958\n",
      "1 0.21842779\n",
      "1 0.16288595\n",
      "1 0.18454964\n",
      "1 0.15433198\n",
      "1 0.1941731\n",
      "1 0.28387767\n",
      "1 0.15300284\n",
      "1 0.22245254\n",
      "1 0.20637554\n",
      "1 0.137422\n",
      "1 0.17809904\n",
      "1 0.25479302\n",
      "1 0.3176989\n",
      "1 0.24389744\n",
      "1 0.17413929\n",
      "1 0.27172244\n",
      "1 0.17296967\n",
      "1 0.26061288\n",
      "1 0.2142265\n",
      "1 0.15652826\n",
      "1 0.19252309\n",
      "1 0.34068695\n",
      "1 0.12781\n",
      "1 0.18085068\n",
      "1 0.18665422\n",
      "1 0.17937054\n",
      "1 0.24284294\n",
      "1 0.2134216\n",
      "1 0.15965171\n",
      "1 0.19553106\n",
      "1 0.2109196\n",
      "1 0.18068588\n",
      "1 0.23028351\n",
      "1 0.17707208\n",
      "1 0.2989216\n",
      "1 0.30864856\n",
      "1 0.2588323\n",
      "1 0.15446766\n",
      "1 0.18856017\n",
      "1 0.25338116\n",
      "1 0.16963327\n",
      "1 0.22034124\n",
      "1 0.17684612\n",
      "1 0.25587836\n",
      "1 0.24077047\n",
      "1 0.34688693\n",
      "1 0.20908687\n",
      "1 0.24532245\n",
      "1 0.29052588\n",
      "1 0.14708161\n",
      "1 0.18407758\n",
      "1 0.3352359\n",
      "1 0.09060394\n",
      "1 0.2568991\n",
      "1 0.17704943\n",
      "1 0.16345327\n",
      "1 0.19239868\n",
      "1 0.24924211\n",
      "1 0.12889437\n",
      "1 0.19014338\n",
      "1 0.17945741\n",
      "1 0.23171665\n",
      "1 0.15182713\n",
      "1 0.1531859\n",
      "1 0.3196989\n",
      "1 0.25844994\n",
      "1 0.21582463\n",
      "1 0.22671098\n",
      "1 0.1283717\n",
      "1 0.28997236\n",
      "1 0.3481372\n",
      "1 0.19981882\n",
      "1 0.1779806\n",
      "1 0.16378376\n",
      "1 0.17396624\n",
      "1 0.09747076\n",
      "1 0.28269726\n",
      "1 0.124552645\n",
      "1 0.26297677\n",
      "1 0.15407646\n",
      "1 0.26503015\n",
      "1 0.1919283\n",
      "1 0.1433936\n",
      "1 0.14822382\n",
      "1 0.19021453\n",
      "1 0.22714077\n",
      "1 0.2520618\n",
      "1 0.0978798\n",
      "1 0.21034811\n",
      "1 0.22425935\n",
      "1 0.22862674\n",
      "1 0.20236878\n",
      "1 0.18166806\n",
      "1 0.20704676\n",
      "1 0.22483575\n",
      "1 0.24575359\n",
      "1 0.28378892\n",
      "1 0.17772445\n",
      "1 0.14117649\n",
      "1 0.19443423\n",
      "1 0.28732032\n",
      "1 0.22513746\n",
      "1 0.26436263\n",
      "1 0.18115422\n",
      "1 0.3311207\n",
      "1 0.26028618\n",
      "1 0.14795998\n",
      "1 0.20262119\n",
      "1 0.20311569\n",
      "1 0.1470316\n",
      "1 0.11373063\n",
      "1 0.2308695\n",
      "1 0.23249155\n",
      "1 0.19938013\n",
      "1 0.35933265\n",
      "1 0.27203447\n",
      "1 0.11547892\n",
      "1 0.18449876\n",
      "1 0.23530528\n",
      "1 0.16859037\n",
      "1 0.27650827\n",
      "1 0.24692096\n",
      "1 0.12520553\n",
      "1 0.3429873\n",
      "1 0.21397203\n",
      "1 0.15095828\n",
      "1 0.23773822\n",
      "1 0.31153837\n",
      "1 0.2165346\n",
      "1 0.20849374\n",
      "1 0.1890977\n",
      "1 0.14519693\n",
      "1 0.20663917\n",
      "1 0.16242275\n",
      "1 0.12710041\n",
      "1 0.38030723\n",
      "1 0.23703633\n",
      "1 0.24450624\n",
      "1 0.32141858\n",
      "1 0.402973\n",
      "1 0.18708174\n",
      "1 0.25118342\n",
      "1 0.19412984\n",
      "1 0.2968193\n",
      "1 0.33179665\n",
      "1 0.21441688\n",
      "1 0.26376343\n",
      "1 0.21622181\n",
      "1 0.23133583\n",
      "1 0.2502068\n",
      "1 0.19678307\n",
      "1 0.15378493\n",
      "1 0.18171301\n",
      "1 0.21998061\n",
      "1 0.14320609\n",
      "1 0.21249872\n",
      "1 0.16705424\n",
      "1 0.24230543\n",
      "1 0.18566467\n",
      "1 0.28073493\n",
      "1 0.17471863\n",
      "1 0.34072772\n",
      "1 0.23294456\n",
      "1 0.22556132\n",
      "1 0.19780889\n",
      "1 0.22028647\n",
      "1 0.14596124\n",
      "1 0.31901193\n",
      "1 0.21918088\n",
      "1 0.24164057\n",
      "1 0.18319486\n",
      "1 0.21338986\n",
      "1 0.17175779\n",
      "1 0.14302963\n",
      "1 0.12372078\n",
      "1 0.16126654\n",
      "1 0.13070151\n",
      "1 0.20190834\n",
      "1 0.32866204\n",
      "1 0.14450681\n",
      "1 0.12983172\n",
      "1 0.2726821\n",
      "1 0.19532065\n",
      "1 0.22669877\n",
      "1 0.19308662\n",
      "1 0.1528292\n",
      "1 0.17773856\n",
      "1 0.085508116\n",
      "1 0.078144975\n",
      "1 0.17122684\n",
      "1 0.23232536\n",
      "1 0.16252448\n",
      "1 0.27859545\n",
      "1 0.300269\n",
      "1 0.13994189\n",
      "1 0.20085834\n",
      "1 0.16245264\n",
      "1 0.17638631\n",
      "1 0.14916801\n",
      "1 0.17199817\n",
      "1 0.14754972\n",
      "1 0.21335119\n",
      "1 0.26897973\n",
      "1 0.20274727\n",
      "1 0.24812058\n",
      "1 0.27168977\n",
      "1 0.21798423\n",
      "1 0.18429372\n",
      "1 0.13622983\n",
      "1 0.15419796\n",
      "1 0.2122201\n",
      "1 0.23449843\n",
      "2 0.15773804\n",
      "2 0.15959625\n",
      "2 0.17137305\n",
      "2 0.11543435\n",
      "2 0.117174156\n",
      "2 0.20574494\n",
      "2 0.09959051\n",
      "2 0.16453044\n",
      "2 0.12516034\n",
      "2 0.15504798\n",
      "2 0.16810715\n",
      "2 0.18996182\n",
      "2 0.31793004\n",
      "2 0.13562043\n",
      "2 0.2058957\n",
      "2 0.12424036\n",
      "2 0.1667153\n",
      "2 0.26578787\n",
      "2 0.18424144\n",
      "2 0.22450714\n",
      "2 0.20087376\n",
      "2 0.21634446\n",
      "2 0.19735284\n",
      "2 0.17181234\n",
      "2 0.16763996\n",
      "2 0.124928504\n",
      "2 0.24194625\n",
      "2 0.40087965\n",
      "2 0.27649567\n",
      "2 0.10665116\n",
      "2 0.19191818\n",
      "2 0.19108245\n",
      "2 0.143813\n",
      "2 0.14352402\n",
      "2 0.17625046\n",
      "2 0.21736342\n",
      "2 0.12368868\n",
      "2 0.18375713\n",
      "2 0.14366315\n",
      "2 0.16537987\n",
      "2 0.24623333\n",
      "2 0.21711443\n",
      "2 0.23748028\n",
      "2 0.2263\n",
      "2 0.19970465\n",
      "2 0.18462029\n",
      "2 0.22839025\n",
      "2 0.30628252\n",
      "2 0.22380944\n",
      "2 0.1496243\n",
      "2 0.15413815\n",
      "2 0.09416764\n",
      "2 0.15310119\n",
      "2 0.5271133\n",
      "2 0.12550247\n",
      "2 0.21717769\n",
      "2 0.19749577\n",
      "2 0.20147578\n",
      "2 0.26207286\n",
      "2 0.17426491\n",
      "2 0.2030412\n",
      "2 0.09686453\n",
      "2 0.23192509\n",
      "2 0.14546835\n",
      "2 0.119938254\n",
      "2 0.11690501\n",
      "2 0.15010826\n",
      "2 0.13551964\n",
      "2 0.1754126\n",
      "2 0.23831287\n",
      "2 0.1418073\n",
      "2 0.18931243\n",
      "2 0.22130959\n",
      "2 0.1596356\n",
      "2 0.12406214\n",
      "2 0.1439737\n",
      "2 0.14568308\n",
      "2 0.15643632\n",
      "2 0.16919462\n",
      "2 0.19838953\n",
      "2 0.21760553\n",
      "2 0.12229663\n",
      "2 0.10660778\n",
      "2 0.31322488\n",
      "2 0.2605917\n",
      "2 0.12757462\n",
      "2 0.11596242\n",
      "2 0.09301924\n",
      "2 0.10993931\n",
      "2 0.1474545\n",
      "2 0.25145414\n",
      "2 0.21842611\n",
      "2 0.17802612\n",
      "2 0.27146918\n",
      "2 0.14286001\n",
      "2 0.1369556\n",
      "2 0.16385493\n",
      "2 0.122656494\n",
      "2 0.20726739\n",
      "2 0.12332344\n",
      "2 0.19634013\n",
      "2 0.21242364\n",
      "2 0.14643401\n",
      "2 0.17284553\n",
      "2 0.16106378\n",
      "2 0.12690917\n",
      "2 0.12101105\n",
      "2 0.24133496\n",
      "2 0.2821646\n",
      "2 0.21045989\n",
      "2 0.16967803\n",
      "2 0.21311261\n",
      "2 0.19855088\n",
      "2 0.08667433\n",
      "2 0.20628913\n",
      "2 0.12534092\n",
      "2 0.18441375\n",
      "2 0.19740108\n",
      "2 0.14822105\n",
      "2 0.17941038\n",
      "2 0.2684255\n",
      "2 0.11933265\n",
      "2 0.15223208\n",
      "2 0.22173314\n",
      "2 0.29614085\n",
      "2 0.29878002\n",
      "2 0.1402259\n",
      "2 0.12253434\n",
      "2 0.15446834\n",
      "2 0.1805304\n",
      "2 0.19870688\n",
      "2 0.17244135\n",
      "2 0.17328751\n",
      "2 0.26451465\n",
      "2 0.20315908\n",
      "2 0.17695038\n",
      "2 0.14246067\n",
      "2 0.12457546\n",
      "2 0.2752071\n",
      "2 0.2116146\n",
      "2 0.20304191\n",
      "2 0.38410902\n",
      "2 0.17126058\n",
      "2 0.16405302\n",
      "2 0.2986841\n",
      "2 0.18645397\n",
      "2 0.15094452\n",
      "2 0.18165718\n",
      "2 0.20246348\n",
      "2 0.15073551\n",
      "2 0.23904046\n",
      "2 0.15867634\n",
      "2 0.15661569\n",
      "2 0.21010774\n",
      "2 0.16688588\n",
      "2 0.17030838\n",
      "2 0.16005775\n",
      "2 0.18017259\n",
      "2 0.12119612\n",
      "2 0.15411693\n",
      "2 0.27782238\n",
      "2 0.19370681\n",
      "2 0.2464589\n",
      "2 0.2160937\n",
      "2 0.104929954\n",
      "2 0.22450513\n",
      "2 0.12584665\n",
      "2 0.12884015\n",
      "2 0.19335693\n",
      "2 0.13905871\n",
      "2 0.15544493\n",
      "2 0.12261733\n",
      "2 0.2566089\n",
      "2 0.20441964\n",
      "2 0.14721058\n",
      "2 0.15388764\n",
      "2 0.14231674\n",
      "2 0.17849998\n",
      "2 0.17843267\n",
      "2 0.11368756\n",
      "2 0.19911331\n",
      "2 0.22083311\n",
      "2 0.16576059\n",
      "2 0.13532093\n",
      "2 0.20108552\n",
      "2 0.13140792\n",
      "2 0.16000813\n",
      "2 0.28685808\n",
      "2 0.19233781\n",
      "2 0.20891194\n",
      "2 0.208677\n",
      "2 0.23789117\n",
      "2 0.15453568\n",
      "2 0.20901543\n",
      "2 0.19947803\n",
      "2 0.2049322\n",
      "2 0.34554744\n",
      "2 0.15294899\n",
      "2 0.18035741\n",
      "2 0.13154414\n",
      "2 0.17164217\n",
      "2 0.16586237\n",
      "2 0.19498426\n",
      "2 0.12865923\n",
      "2 0.17863111\n",
      "2 0.18556146\n",
      "2 0.25510946\n",
      "2 0.12844634\n",
      "2 0.1940589\n",
      "2 0.16538812\n",
      "2 0.19433692\n",
      "2 0.15334584\n",
      "2 0.17414619\n",
      "2 0.2032306\n",
      "2 0.26083592\n",
      "2 0.23564944\n",
      "2 0.14846896\n",
      "2 0.2654845\n",
      "2 0.102269895\n",
      "2 0.1752153\n",
      "2 0.17943521\n",
      "2 0.096564725\n",
      "2 0.21535046\n",
      "2 0.11876651\n",
      "2 0.16932076\n",
      "2 0.14196704\n",
      "2 0.26896775\n",
      "2 0.21003386\n",
      "2 0.14233792\n",
      "2 0.11213741\n",
      "2 0.18639655\n",
      "2 0.18496385\n",
      "2 0.18639912\n",
      "2 0.1745212\n",
      "2 0.23146038\n",
      "2 0.18770264\n",
      "2 0.18012847\n",
      "2 0.18172728\n",
      "2 0.22912227\n",
      "2 0.166487\n",
      "2 0.13058345\n",
      "2 0.13149673\n",
      "2 0.16432296\n",
      "2 0.15404145\n",
      "2 0.14052711\n",
      "2 0.17492905\n",
      "2 0.12866397\n",
      "2 0.12757456\n",
      "2 0.18315636\n",
      "2 0.18225068\n",
      "2 0.18046176\n",
      "2 0.2918772\n",
      "2 0.19696213\n",
      "2 0.16723457\n",
      "2 0.2003537\n",
      "2 0.16616108\n",
      "2 0.11000752\n",
      "2 0.1487784\n",
      "2 0.14655839\n",
      "2 0.13645627\n",
      "2 0.14898646\n",
      "2 0.22773065\n",
      "2 0.1790124\n",
      "2 0.107708275\n",
      "2 0.23614061\n",
      "2 0.16469708\n",
      "2 0.12517962\n",
      "3 0.20104274\n",
      "3 0.15637174\n",
      "3 0.13393995\n",
      "3 0.15150195\n",
      "3 0.12827788\n",
      "3 0.23111114\n",
      "3 0.14774644\n",
      "3 0.115229174\n",
      "3 0.18213196\n",
      "3 0.17205462\n",
      "3 0.22344914\n",
      "3 0.1923879\n",
      "3 0.12936383\n",
      "3 0.17639755\n",
      "3 0.16632298\n",
      "3 0.16476335\n",
      "3 0.28651875\n",
      "3 0.28376716\n",
      "3 0.2323495\n",
      "3 0.15730946\n",
      "3 0.14037618\n",
      "3 0.2975256\n",
      "3 0.16621077\n",
      "3 0.25462216\n",
      "3 0.22257268\n",
      "3 0.23548372\n",
      "3 0.24404453\n",
      "3 0.16341998\n",
      "3 0.1619165\n",
      "3 0.22285295\n",
      "3 0.192192\n",
      "3 0.13601944\n",
      "3 0.26363236\n",
      "3 0.1685746\n",
      "3 0.22265077\n",
      "3 0.19327116\n",
      "3 0.17945707\n",
      "3 0.17438291\n",
      "3 0.23072445\n",
      "3 0.29622993\n",
      "3 0.111415416\n",
      "3 0.18928334\n",
      "3 0.17560716\n",
      "3 0.18954125\n",
      "3 0.26594502\n",
      "3 0.21955219\n",
      "3 0.21941514\n",
      "3 0.18430665\n",
      "3 0.23519175\n",
      "3 0.16149761\n",
      "3 0.19372025\n",
      "3 0.15184718\n",
      "3 0.25713366\n",
      "3 0.18373457\n",
      "3 0.3167283\n",
      "3 0.23172706\n",
      "3 0.15648319\n",
      "3 0.18811873\n",
      "3 0.13824892\n",
      "3 0.26818165\n",
      "3 0.27061066\n",
      "3 0.19561389\n",
      "3 0.16434969\n",
      "3 0.13311732\n",
      "3 0.22624758\n",
      "3 0.17354187\n",
      "3 0.2021004\n",
      "3 0.26478153\n",
      "3 0.23946421\n",
      "3 0.19658971\n",
      "3 0.19423473\n",
      "3 0.34974214\n",
      "3 0.1611838\n",
      "3 0.1613248\n",
      "3 0.15909399\n",
      "3 0.40911344\n",
      "3 0.19301662\n",
      "3 0.1831255\n",
      "3 0.19274795\n",
      "3 0.11258\n",
      "3 0.11716637\n",
      "3 0.29332656\n",
      "3 0.18343967\n",
      "3 0.21218112\n",
      "3 0.21574125\n",
      "3 0.19895074\n",
      "3 0.14685686\n",
      "3 0.19942869\n",
      "3 0.157781\n",
      "3 0.23077275\n",
      "3 0.14989734\n",
      "3 0.23707274\n",
      "3 0.2137757\n",
      "3 0.19109952\n",
      "3 0.16988951\n",
      "3 0.18076637\n",
      "3 0.15704796\n",
      "3 0.171282\n",
      "3 0.20523405\n",
      "3 0.19388866\n",
      "3 0.20424767\n",
      "3 0.19951674\n",
      "3 0.17682464\n",
      "3 0.31077206\n",
      "3 0.24483724\n",
      "3 0.22526458\n",
      "3 0.13648245\n",
      "3 0.15772346\n",
      "3 0.17508653\n",
      "3 0.2295846\n",
      "3 0.24806142\n",
      "3 0.22351587\n",
      "3 0.21500587\n",
      "3 0.19767171\n",
      "3 0.17468822\n",
      "3 0.21343482\n",
      "3 0.14535776\n",
      "3 0.18626025\n",
      "3 0.19923832\n",
      "3 0.14137228\n",
      "3 0.23108324\n",
      "3 0.21689436\n",
      "3 0.21644543\n",
      "3 0.1396897\n",
      "3 0.16639519\n",
      "3 0.21555248\n",
      "3 0.23094288\n",
      "3 0.13338806\n",
      "3 0.2142983\n",
      "3 0.14432374\n",
      "3 0.15820937\n",
      "3 0.19886708\n",
      "3 0.13679492\n",
      "3 0.15755095\n",
      "3 0.18413466\n",
      "3 0.25320762\n",
      "3 0.14777215\n",
      "3 0.24753062\n",
      "3 0.156469\n",
      "3 0.18911326\n",
      "3 0.18172416\n",
      "3 0.200268\n",
      "3 0.20853242\n",
      "3 0.14755481\n",
      "3 0.21606022\n",
      "3 0.19639806\n",
      "3 0.1450347\n",
      "3 0.18558395\n",
      "3 0.2225276\n",
      "3 0.12287097\n",
      "3 0.20231608\n",
      "3 0.19859454\n",
      "3 0.22557253\n",
      "3 0.1941736\n",
      "3 0.1951608\n",
      "3 0.17590602\n",
      "3 0.17929451\n",
      "3 0.13869764\n",
      "3 0.20312956\n",
      "3 0.21835439\n",
      "3 0.21944925\n",
      "3 0.2056987\n",
      "3 0.23936832\n",
      "3 0.2177504\n",
      "3 0.24877608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.207554\n",
      "3 0.178126\n",
      "3 0.22611445\n",
      "3 0.20877737\n",
      "3 0.28186154\n",
      "3 0.18291561\n",
      "3 0.19764228\n",
      "3 0.13749732\n",
      "3 0.08124745\n",
      "3 0.3591737\n",
      "3 0.15593195\n",
      "3 0.20672588\n",
      "3 0.1836293\n",
      "3 0.19851214\n",
      "3 0.2765779\n",
      "3 0.13200268\n",
      "3 0.18823302\n",
      "3 0.26419115\n",
      "3 0.22079965\n",
      "3 0.17464751\n",
      "3 0.27454245\n",
      "3 0.20554616\n",
      "3 0.20001186\n",
      "3 0.23259811\n",
      "3 0.13230702\n",
      "3 0.18133911\n",
      "3 0.1479576\n",
      "3 0.123533055\n",
      "3 0.14811099\n",
      "3 0.21212693\n",
      "3 0.1322181\n",
      "3 0.13920295\n",
      "3 0.11359023\n",
      "3 0.15736796\n",
      "3 0.23218934\n",
      "3 0.18517256\n",
      "3 0.16865173\n",
      "3 0.16218393\n",
      "3 0.2913058\n",
      "3 0.1838196\n",
      "3 0.12912336\n",
      "3 0.20417914\n",
      "3 0.18680489\n",
      "3 0.17268793\n",
      "3 0.22659034\n",
      "3 0.14026782\n",
      "3 0.22651537\n",
      "3 0.2571268\n",
      "3 0.109995596\n",
      "3 0.19648382\n",
      "3 0.16160336\n",
      "3 0.17966178\n",
      "3 0.1690512\n",
      "3 0.2602818\n",
      "3 0.22563592\n",
      "3 0.19278027\n",
      "3 0.15010452\n",
      "3 0.14716633\n",
      "3 0.19668627\n",
      "3 0.2115961\n",
      "3 0.3062374\n",
      "3 0.16068219\n",
      "3 0.17146112\n",
      "3 0.17446741\n",
      "3 0.18519773\n",
      "3 0.17245978\n",
      "3 0.14772159\n",
      "3 0.20848729\n",
      "3 0.17671598\n",
      "3 0.22403498\n",
      "3 0.3138336\n",
      "3 0.1485486\n",
      "3 0.20166478\n",
      "3 0.12629506\n",
      "3 0.18495941\n",
      "3 0.17796928\n",
      "3 0.17411709\n",
      "3 0.15289554\n",
      "3 0.18560198\n",
      "3 0.19705349\n",
      "3 0.25614637\n",
      "3 0.2278657\n",
      "3 0.19342539\n",
      "3 0.17545426\n",
      "3 0.14742872\n",
      "3 0.18268903\n",
      "3 0.1827458\n",
      "3 0.16847098\n",
      "3 0.16526338\n",
      "3 0.23159058\n",
      "3 0.108899295\n",
      "3 0.15721282\n",
      "3 0.19674802\n",
      "3 0.16690904\n",
      "3 0.23572074\n",
      "3 0.29144657\n",
      "3 0.17685184\n",
      "3 0.17379694\n",
      "3 0.19385646\n",
      "3 0.16498804\n",
      "3 0.17200679\n",
      "3 0.24340059\n",
      "4 0.15027194\n",
      "4 0.18868059\n",
      "4 0.18758668\n",
      "4 0.23077406\n",
      "4 0.21787542\n",
      "4 0.28002506\n",
      "4 0.3425417\n",
      "4 0.13977255\n",
      "4 0.45361105\n",
      "4 0.24844527\n",
      "4 0.14581986\n",
      "4 0.123038344\n",
      "4 0.20102982\n",
      "4 0.20599347\n",
      "4 0.22495563\n",
      "4 0.29270285\n",
      "4 0.16861168\n",
      "4 0.2049827\n",
      "4 0.24792483\n",
      "4 0.22536168\n",
      "4 0.2115022\n",
      "4 0.25337535\n",
      "4 0.30635825\n",
      "4 0.19370586\n",
      "4 0.2499439\n",
      "4 0.2411993\n",
      "4 0.22932883\n",
      "4 0.1599091\n",
      "4 0.284761\n",
      "4 0.22280866\n",
      "4 0.23480068\n",
      "4 0.3509248\n",
      "4 0.20679584\n",
      "4 0.16754983\n",
      "4 0.12531567\n",
      "4 0.19319148\n",
      "4 0.17129186\n",
      "4 0.29614577\n",
      "4 0.26854908\n",
      "4 0.30911198\n",
      "4 0.23962349\n",
      "4 0.40813968\n",
      "4 0.17630363\n",
      "4 0.21469733\n",
      "4 0.21506417\n",
      "4 0.20096672\n",
      "4 0.2838937\n",
      "4 0.310711\n",
      "4 0.1891468\n",
      "4 0.4274193\n",
      "4 0.20882678\n",
      "4 0.09603428\n",
      "4 0.18241134\n",
      "4 0.36513385\n",
      "4 0.11131643\n",
      "4 0.22260816\n",
      "4 0.14508832\n",
      "4 0.20048107\n",
      "4 0.16174884\n",
      "4 0.22320916\n",
      "4 0.21364474\n",
      "4 0.1237907\n",
      "4 0.23488498\n",
      "4 0.18960124\n",
      "4 0.172446\n",
      "4 0.31382477\n",
      "4 0.2592216\n",
      "4 0.19866072\n",
      "4 0.19554476\n",
      "4 0.24090755\n",
      "4 0.166831\n",
      "4 0.389869\n",
      "4 0.15561387\n",
      "4 0.17386885\n",
      "4 0.16582331\n",
      "4 0.24666691\n",
      "4 0.19138502\n",
      "4 0.22109818\n",
      "4 0.23515287\n",
      "4 0.14295626\n",
      "4 0.1388757\n",
      "4 0.24468696\n",
      "4 0.21299988\n",
      "4 0.11811736\n",
      "4 0.17795524\n",
      "4 0.26621962\n",
      "4 0.21164875\n",
      "4 0.21828845\n",
      "4 0.26180324\n",
      "4 0.3085631\n",
      "4 0.17525145\n",
      "4 0.24455243\n",
      "4 0.18568851\n",
      "4 0.30857974\n",
      "4 0.19794883\n",
      "4 0.14728051\n",
      "4 0.1941336\n",
      "4 0.15104769\n",
      "4 0.14102261\n",
      "4 0.33390138\n",
      "4 0.20672186\n",
      "4 0.1544267\n",
      "4 0.12919183\n",
      "4 0.16926673\n",
      "4 0.15129976\n",
      "4 0.1401066\n",
      "4 0.22463901\n",
      "4 0.32376865\n",
      "4 0.2624356\n",
      "4 0.3199514\n",
      "4 0.16185756\n",
      "4 0.16379225\n",
      "4 0.25245398\n",
      "4 0.43831292\n",
      "4 0.11494772\n",
      "4 0.15454377\n",
      "4 0.38847277\n",
      "4 0.28518716\n",
      "4 0.18330202\n",
      "4 0.13127731\n",
      "4 0.25421265\n",
      "4 0.30184188\n",
      "4 0.21009251\n",
      "4 0.16736807\n",
      "4 0.30803367\n",
      "4 0.19107634\n",
      "4 0.26704726\n",
      "4 0.17630413\n",
      "4 0.36629647\n",
      "4 0.17086911\n",
      "4 0.17399828\n",
      "4 0.31112212\n",
      "4 0.14580394\n",
      "4 0.26753837\n",
      "4 0.23347303\n",
      "4 0.22367944\n",
      "4 0.2204277\n",
      "4 0.1960957\n",
      "4 0.18177748\n",
      "4 0.16373828\n",
      "4 0.19028598\n",
      "4 0.28010336\n",
      "4 0.14223093\n",
      "4 0.2391317\n",
      "4 0.1466379\n",
      "4 0.33371758\n",
      "4 0.39278504\n",
      "4 0.20904094\n",
      "4 0.2279214\n",
      "4 0.11484717\n",
      "4 0.22516404\n",
      "4 0.14658497\n",
      "4 0.1710399\n",
      "4 0.2863346\n",
      "4 0.35297853\n",
      "4 0.12531097\n",
      "4 0.20468542\n",
      "4 0.27349794\n",
      "4 0.6262008\n",
      "4 0.15628792\n",
      "4 0.26341796\n",
      "4 0.18485239\n",
      "4 0.105639495\n",
      "4 0.14430702\n",
      "4 0.20641243\n",
      "4 0.15966246\n",
      "4 0.18816522\n",
      "4 0.25779447\n",
      "4 0.17047532\n",
      "4 0.22589599\n",
      "4 0.34397376\n",
      "4 0.17852116\n",
      "4 0.12796633\n",
      "4 0.23045453\n",
      "4 0.20451444\n",
      "4 0.22490562\n",
      "4 0.19445184\n",
      "4 0.18955757\n",
      "4 0.1291557\n",
      "4 0.15981153\n",
      "4 0.180415\n",
      "4 0.23796695\n",
      "4 0.33238792\n",
      "4 0.31677204\n",
      "4 0.15834677\n",
      "4 0.12839784\n",
      "4 0.22937874\n",
      "4 0.31466773\n",
      "4 0.21485245\n",
      "4 0.092397645\n",
      "4 0.2690789\n",
      "4 0.115348466\n",
      "4 0.113011844\n",
      "4 0.49144763\n",
      "4 0.3765175\n",
      "4 0.21420118\n",
      "4 0.17996074\n",
      "4 0.27150744\n",
      "4 0.21550049\n",
      "4 0.27974486\n",
      "4 0.2101131\n",
      "4 0.1868659\n",
      "4 0.29660502\n",
      "4 0.23210132\n",
      "4 0.28888384\n",
      "4 0.14137343\n",
      "4 0.1733764\n",
      "4 0.19991383\n",
      "4 0.18696718\n",
      "4 0.15583022\n",
      "4 0.24231906\n",
      "4 0.19037695\n",
      "4 0.20508845\n",
      "4 0.15239923\n",
      "4 0.16339286\n",
      "4 0.13138603\n",
      "4 0.21731636\n",
      "4 0.24566193\n",
      "4 0.12400548\n",
      "4 0.23544109\n",
      "4 0.37821326\n",
      "4 0.29612944\n",
      "4 0.2708509\n",
      "4 0.21754119\n",
      "4 0.1984906\n",
      "4 0.18161337\n",
      "4 0.21854115\n",
      "4 0.34573862\n",
      "4 0.26270548\n",
      "4 0.17338508\n",
      "4 0.20749268\n",
      "4 0.16347224\n",
      "4 0.21079609\n",
      "4 0.24921875\n",
      "4 0.19303536\n",
      "4 0.19445859\n",
      "4 0.21470745\n",
      "4 0.17072806\n",
      "4 0.20121656\n",
      "4 0.20743892\n",
      "4 0.22998303\n",
      "4 0.18223906\n",
      "4 0.16731629\n",
      "4 0.27663296\n",
      "4 0.18383896\n",
      "4 0.19803458\n",
      "4 0.14288114\n",
      "4 0.19448598\n",
      "4 0.23751083\n",
      "4 0.15407999\n",
      "4 0.37387863\n",
      "4 0.2493241\n",
      "4 0.24075462\n",
      "4 0.33118036\n",
      "4 0.13713504\n",
      "4 0.15825991\n",
      "4 0.22726431\n",
      "4 0.27459878\n",
      "4 0.22096883\n",
      "4 0.18603897\n",
      "4 0.19685821\n",
      "4 0.18729492\n",
      "4 0.22849938\n",
      "4 0.26075652\n",
      "4 0.20224759\n",
      "4 0.1942642\n",
      "4 0.35002804\n"
     ]
    }
   ],
   "source": [
    "for i,d in enumerate(Sdb_descriptors):\n",
    "    print(Sdb[i].cls,np.max(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (ex3)",
   "language": "python",
   "name": "ex3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
